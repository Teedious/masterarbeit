Während der Arbeit an der nebenläufigen Architektur sind einige Möglichkeiten zum Vorschein gekommen, die implementiert werden können, um das nun bestehende System weiter zu verbessern.
\paragraph{Jobsystem mit PriorityQueue}
Die offensichtlichste Möglichkeit, die nebenläufige Architektur weiter voranzutreiben, ist bereits in der Arbeit behandelt worden. Zwar bietet das Jobsystem durch die Nutzung von zwei getrennten Thread-Pools die Möglichkeit, Tasks mit unterschiedlichen Prioritäten zu definieren, allerdings hat das aktuell nur den Effekt, dass sich die Tasks durch die unterschiedlichen Thread-Pools nicht behindern. Tasks mit höherer Priorität werden nicht eher ausgeführt als Task mit niedriger Priorität. Außerdem ist durch die aktuelle Implementierung die Möglichkeit verloren gegangen, die Anzahl der Java-Threads genau auf die Anzahl der Hardware-Threads anzupassen. Das kann, wie bereits in den Grundlagen beschrieben, dazu führen, dass die Threads sich durch häufige Kontextwechsel gegenseitig behindern.

Die Lösung dafür ist die Implementierung eines Jobsystems mit einer funktionierenden Priorisierung über eine Prioritäts-Warteschlange für die Tasks. Damit wird eine tatsächliche Priorisierung von Tasks ermöglicht. Weiter können mehr als nur zwei verschiedene Prioritäten festgelegt werden und die Anzahl der Threads lässt sich wieder exakt abstimmen, sodass die Konkurrenz über die Hardware-Threads möglichst gering ist.

Eine weitere Möglichkeit die nebenläufige Architektur der Blocklib zu verbessern ist, die bestehende Simulation so anzupassen, dass mehr Aufgaben in Jobs ausgelagert werden, sodass die verfügbaren Hardware-Threads besser ausgenutzt werden können. Damit in Verbindung steht die Möglichkeit, verstärkt sogenanntes Batching einzusetzen. Das bedeutet, dass Methoden weniger tief geschachtelt sind, sondern stattdessen gleiche Aufrufe gemeinsam abgearbeitet werden.
Ein Beispiel für einen tief geschachtelten Methodenaufruf wäre, dass die \code{hit(...)}-Methode eines Nicht-Spieler-Charakters (NSCs) die \code{checkDefense(...)}-Methode des Spielers auslöst und sich eine Methoden-Kaskade \code{decreaseHealth(...)} $\to$ \code{setHealth(...)} $\to$ \code{checkDamageThreshold(...)} $\to$ \code{setBleeding(...)} $\to$ \code{addBloodTexture(...)} $\to$ \code{startHitSound(...)} ergibt, die verschiedenste Systeme betrifft. Stattdessen könnte der Methodenaufruf auch so aussehen \code{hit(...)} $\to$ \code{addToSetHealthList(...)}. Dann könnten erst alle 
\code{hit(...)}-Methoden, sogar nebenläufig, abgearbeitet werden und eine Liste erzeugen, die dann im nächsten Schritt, wiederum nebenläufig, abgearbeitet werden könnte. 

\paragraph{Thread Affinity}
Ein Thema, das in der Arbeit bisher nicht behandelt worden ist, ist die Frage, auf welchem Hardware-Thread ein Java-Thread schlussendlich ausgeführt wird. Spielentwickler in der Spielindustrie beschäftigen sich aber sehr wohl damit, da dies die Leistung der Software beeinflussen kann~\cite{Gyrling2015}. \emph{Thread Affinity} bezeichnet das Konzept der Zuordnung von Anwendungs-Threads (im Fall der Blocklib Java-Threads) zu Hardware-Threads. Ein bestimmter Java-Thread soll dann beispielsweise immer nur auf Hardware-Thread 1 ausgeführt werden. Thread Affinity kann die Leistung einer Software wie der Blocklib erhöhen, da sie unnötige Kontextwechsel verhindert. Dies lässt sich wie folgt veranschaulichen.

Angenommen, die Blocklib wird auf einem Rechner mit vier Hardware-Threads ausgeführt und besitzt inzwischen ein Jobsystem, das die Anzahl der Java-Threads genau auf die Hardware-Threads anpasst. Dann können prinzipiell alle erzeugten Java-Threads dauerhaft auf je einem Hardware-Thread ausgeführt werden. Die Blocklib ist allerdings nicht das einzige Programm, das auf dem Rechner ausgeführt wird, daher wird irgendwann einer der Java-Threads durch irgendein anderes Programm unterbrochen (\emph{nicht} das \code{interrupt()} in Java) und muss danach zur weiteren Ausführung einem Hardware-Thread zugeordnet werden. Da die restlichen Java-Threads der Blocklib bereits sehr lange ausgeführt werden, führt das nun dazu, dass einer der noch laufenden Threads der Blocklib durch den gerade unterbrochenen Thread ausgetauscht wird, was zu einem weiteren Kontextwechsel führt. Das führt sich kaskadenartig fort, bis alle Java-Threads der Blocklib einmal unterbrochen worden sind. Eine einzige Unterbrechung führt so also zu vier Kontextwechseln. Je höher die Anzahl der Hardware-Threads, desto höher ist auch die Anzahl der unnötigen Kontextwechsel, die jeweils Zeit benötigen.

Dieses Problem lässt sich durch eine feste Zuordnung von Java-Threads zu Hardware-Threads lösen. Tritt nun eine Unterbrechung auf, wird der Thread nicht auf einen anderen Hardware-Thread umgelenkt, sondern wartet, bis der belegte Hardware-Thread wieder frei ist und führt dann die Ausführung fort. Eine Unterbrechung führt nur zu einem Kontextwechsel, egal wie viele Hardware-Threads vorhanden sind.

Die Implementierung von Thread Affinity ist in Java allerdings nicht trivial, da Java selbst keine Möglichkeiten bietet Java-Threads an Hardware-Threads zu binden. Daher muss diese Funktionalität über das Java Native Interface (JNI) oder Java Native Access (JNA), also mit plattformspezifischen Funktionen, implementiert werden. Es lassen sich allerdings auch Implementierungen und Bibliotheken finden, die diese Funktionalität bereits implementieren~\cite{ChronicleSoftware,Cheremin2011}.